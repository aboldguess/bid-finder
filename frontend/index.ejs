<!DOCTYPE html>
<html>
<head>
  <title>Tender Dashboard</title>
  <link rel="stylesheet" href="/style.css">
</head>
<body>
  <h1>New Tenders</h1>
  <!-- Source selector allows the user to choose which site to scrape -->
  <label for="sourceSelect">Source:</label>
  <select id="sourceSelect">
    <% Object.keys(sources).forEach(key => { %>
      <option value="<%= key %>"><%= sources[key].label %></option>
    <% }) %>
  </select>

  <!-- Button triggers the scraper via AJAX instead of navigating away -->
  <button id="scrapeBtn">Run Scraper Now</button>
  <!-- Area to show status messages while scraping -->
  <div id="status"></div>
  <!-- Rolling feed of progress messages from the scraper -->
  <ul id="feed"></ul>
  <table>
    <tr><th>Title</th><th>Date</th><th>Description</th><th>Link</th></tr>
    <% tenders.forEach(t => { %>
      <tr>
        <td><%= t.title %></td>
        <td><%= t.date %></td>
        <td><%= t.description %></td>
        <td><a href="<%= t.link %>">View</a></td>
      </tr>
    <% }) %>
  </table>
  <!-- Asynchronous scraping logic -->
  <script>
    // When the "Run Scraper Now" button is clicked we open an EventSource
    // connection to /scrape-stream. Progress events are pushed from the server
    // so we can update the UI in real time.
    document.getElementById('scrapeBtn').addEventListener('click', () => {
      const statusEl = document.getElementById('status');
      const feedEl = document.getElementById('feed');

      // Reset any previous messages.
      feedEl.innerHTML = '';
      statusEl.textContent = 'Scraping...';

      // Include the selected source in the request so the server knows which
      // site to scrape.
      const source = document.getElementById('sourceSelect').value;
      const src = new EventSource(`/scrape-stream?source=${encodeURIComponent(source)}`);

      // Handle each message from the server. Regular updates contain progress
      // info while the final message includes `done: true`.
      src.onmessage = e => {
        const data = JSON.parse(e.data);

        if (data.start) {
          // Initial event tells us which source is being scraped.
          statusEl.textContent = `Scraping from ${data.source}...`;
        } else if (data.step === 'found') {
          // The scraper has parsed the page and knows how many tenders exist.
          statusEl.textContent = `Found ${data.count} tenders.`;
        } else if (data.step === 'tender') {
          // Update the rolling feed with each tender processed.
          const li = document.createElement('li');
          li.textContent = `(${data.index}/${data.total}) ${data.title} - ${
            data.inserted ? 'added' : 'skipped'}`;
          feedEl.appendChild(li);
        } else if (data.done) {
          // Final event - show summary and reload the page after a short delay.
          if (data.added === 0) {
            statusEl.textContent = 'No new tenders found.';
          } else {
            statusEl.textContent = `Added ${data.added} new tenders.`;
          }
          setTimeout(() => location.reload(), 1000);
          src.close();
        }
      };

      src.onerror = () => {
        statusEl.textContent = 'Error running scraper.';
        src.close();
      };
    });
  </script>
</body>
</html>
